{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406a3fe0-3675-48d9-867b-304ecade4cd2",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4a921c1-93ca-4f5c-bc07-d491f1f5c9cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.7.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.52.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (0.33.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.14.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.3.1->torch) (69.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.4.26)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade sentence-transformers torch einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990ac5c7-aa53-4108-84bf-8ad0471b2314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 1. Imports ---\n",
    "import os\n",
    "import oci\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.pool import SimpleConnectionPool\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "import numpy as np\n",
    "\n",
    "# --- 2. Configuration ---\n",
    "# Fix the bucket name typo\n",
    "BUCKET_NAME = \"aus-legal-corpus\"  # Corrected from BUCKET_NAME\n",
    "OBJECT_PREFIX = \"\"\n",
    "DOWNLOAD_DIR = \"./data\"\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "\n",
    "# PostgreSQL Config\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"postgres\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"RAbbithole1234##\",\n",
    "    \"host\": \"\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "# OCI Config\n",
    "oci_config = {\n",
    "    \"user\": \"ocid1.user.oc1..aaq\",\n",
    "    \"key_file\": \"./data/oci_api_key.pem\",\n",
    "    \"fingerprint\": \"de:d6\",\n",
    "    \"tenancy\": \"ocid1.tenancy.oc1..aua\",\n",
    "    \"region\": \"us-sanjose-1\"\n",
    "}\n",
    "\n",
    "\n",
    "# --- 3. Connect to OCI and Download Parquet Files ---\n",
    "print(\"🔍 Listing objects in bucket...\")\n",
    "try:\n",
    "    object_storage = oci.object_storage.ObjectStorageClient(oci_config)\n",
    "    namespace = object_storage.get_namespace().data\n",
    "    objects = object_storage.list_objects(namespace, BUCKET_NAME, prefix=OBJECT_PREFIX).data.objects\n",
    "    parquet_files = [obj.name for obj in objects if obj.name.endswith(\".parquet\")]\n",
    "    \n",
    "    if not parquet_files:\n",
    "        raise Exception(\"❌ No .parquet files found. Check bucket, prefix or region.\")\n",
    "        \n",
    "    print(f\"Found {len(parquet_files)} parquet files\")\n",
    "    \n",
    "    for obj_name in parquet_files:\n",
    "        local_file = os.path.join(DOWNLOAD_DIR, os.path.basename(obj_name))\n",
    "        if not os.path.exists(local_file):\n",
    "            print(f\"⬇️ Downloading {obj_name}...\")\n",
    "            with open(local_file, 'wb') as f:\n",
    "                response = object_storage.get_object(namespace, BUCKET_NAME, obj_name)\n",
    "                for chunk in response.data.raw.stream(1024 * 1024, decode_content=False):\n",
    "                    f.write(chunk)\n",
    "    print(\"✅ All Parquet files downloaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in OCI operations: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# --- 4. Load Embedding Model ---\n",
    "print(\"\\nInitializing model...\")\n",
    "try:\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Total memory: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f} GB\")\n",
    "    \n",
    "    model = SentenceTransformer(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True, device=device)\n",
    "    \n",
    "    # Start with smaller batch size and auto-tune\n",
    "    initial_batch_size = 32 if device == 'cuda' else 8\n",
    "    model.max_seq_length = 512  # Might help with memory\n",
    "    \n",
    "    print(\"Warming up GPU...\")\n",
    "    with torch.no_grad(), autocast():\n",
    "        dummy_input = [\"warmup\"] * initial_batch_size\n",
    "        _ = model.encode(dummy_input, batch_size=initial_batch_size)\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"✅ Model loaded successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# --- 5. Connect to PostgreSQL ---\n",
    "print(\"\\nConnecting to PostgreSQL...\")\n",
    "try:\n",
    "    pool = SimpleConnectionPool(1, 4, **DB_CONFIG)\n",
    "    conn = pool.getconn()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Test connection\n",
    "    cursor.execute(\"SELECT 1\")\n",
    "    conn.commit()\n",
    "    print(\"✅ PostgreSQL connection successful\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ PostgreSQL connection failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# --- 6. Create Table ---\n",
    "print(\"\\nEnsuring database table exists...\")\n",
    "try:\n",
    "    cursor.execute(\"\"\"\n",
    "    CREATE EXTENSION IF NOT EXISTS vector;\n",
    "    CREATE TABLE IF NOT EXISTS legal_docs_v3 (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        content TEXT,\n",
    "        jurisdiction TEXT,\n",
    "        source TEXT,\n",
    "        citation TEXT,\n",
    "        embedding VECTOR(768)\n",
    "    );\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "    print(\"✅ Table created/verified\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating table: {str(e)}\")\n",
    "    conn.rollback()\n",
    "\n",
    "# --- 7. Optimized Batch Insert ---\n",
    "def insert_batch(batch):\n",
    "    try:\n",
    "        args_str = \",\".join(cursor.mogrify(\"(%s, %s, %s, %s, %s)\", x).decode(\"utf-8\") for x in batch)\n",
    "        cursor.execute(\"INSERT INTO legal_docs_v3 (content, jurisdiction, source, citation, embedding) VALUES \" + args_str)\n",
    "        conn.commit()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Batch insert failed: {str(e)}\")\n",
    "        conn.rollback()\n",
    "        return False\n",
    "\n",
    "# --- 8. Process Files with Better Progress Tracking ---\n",
    "def process_files():\n",
    "    local_files = sorted([f for f in os.listdir(DOWNLOAD_DIR) if f.endswith(\".parquet\")])\n",
    "    if not local_files:\n",
    "        print(\"❌ No local parquet files found\")\n",
    "        return\n",
    "\n",
    "    for file_idx, file in enumerate(local_files, 1):\n",
    "        print(f\"\\n📂 Processing file {file_idx}/{len(local_files)}: {file}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_parquet(os.path.join(DOWNLOAD_DIR, file))\n",
    "            if \"text\" not in df.columns:\n",
    "                print(f\"⚠️ Skipping {file}, no 'text' column\")\n",
    "                continue\n",
    "\n",
    "            # Prepare all texts first\n",
    "            texts = []\n",
    "            metadata = []\n",
    "            for _, row in df.iterrows():\n",
    "                text = row.get(\"text\", \"\").strip()\n",
    "                if text:\n",
    "                    texts.append(text)\n",
    "                    metadata.append((\n",
    "                        text,\n",
    "                        str(row.get(\"jurisdiction\", \"\")).strip(),\n",
    "                        str(row.get(\"source\", \"\")).strip(),\n",
    "                        str(row.get(\"citation\", \"\")).strip()\n",
    "                    ))\n",
    "\n",
    "            if not texts:\n",
    "                print(\"⚠️ No valid texts found in this file\")\n",
    "                continue\n",
    "\n",
    "            print(f\"📝 Found {len(texts)} texts to process\")\n",
    "            \n",
    "            # Dynamic batch sizing\n",
    "            max_batch_size = 128\n",
    "            current_batch_size = min(32, max_batch_size)\n",
    "            successful_batches = 0\n",
    "            \n",
    "            for i in tqdm(range(0, len(texts), desc=\"Processing\", unit=\"text\"):\n",
    "                batch_texts = texts[i:i+current_batch_size]\n",
    "                batch_metadata = metadata[i:i+current_batch_size]\n",
    "                \n",
    "                try:\n",
    "                    with torch.no_grad(), autocast():\n",
    "                        vectors = model.encode(\n",
    "                            batch_texts,\n",
    "                            batch_size=current_batch_size,\n",
    "                            convert_to_tensor=True,\n",
    "                            normalize_embeddings=True\n",
    "                        ).cpu().numpy().tolist()\n",
    "\n",
    "                    db_batch = [(*meta, vec) for meta, vec in zip(batch_metadata, vectors)]\n",
    "                    \n",
    "                    if insert_batch(db_batch):\n",
    "                        successful_batches += 1\n",
    "                        # Gradually increase batch size if successful\n",
    "                        if successful_batches % 5 == 0 and current_batch_size < max_batch_size:\n",
    "                            current_batch_size = min(current_batch_size * 2, max_batch_size)\n",
    "                            print(f\"⚡ Increased batch size to {current_batch_size}\")\n",
    "                    \n",
    "                except torch.cuda.OutOfMemoryError:\n",
    "                    print(\"⚠️ GPU OOM - reducing batch size\")\n",
    "                    current_batch_size = max(current_batch_size // 2, 8)\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Batch error: {str(e)} - retrying with smaller batch\")\n",
    "                    current_batch_size = max(current_batch_size // 2, 8)\n",
    "                    continue\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing file {file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Actually run the processing\n",
    "process_files()\n",
    "\n",
    "# --- 9. Create HNSW Vector Index ---\n",
    "cursor.execute(\"\"\"\n",
    "CREATE INDEX IF NOT EXISTS legal_docs_hnsw_idx_v3\n",
    "ON legal_docs_v3 USING hnsw (embedding vector_cosine_ops)\n",
    "WITH (m = 16, ef_construction = 64);\n",
    "\"\"\")\n",
    "cursor.execute(\"ANALYZE legal_docs_v3;\")\n",
    "conn.commit()\n",
    "print(\"✅ HNSW vector index created.\")\n",
    "\n",
    "# --- 10. Sentence Search Interface ---\n",
    "def search_query(user_query, top_k=5):\n",
    "    user_vector = model.encode(user_query).tolist()\n",
    "    query = \"\"\"\n",
    "    SELECT content, jurisdiction, source, citation,\n",
    "           1 - (embedding <#> %s::vector) AS similarity\n",
    "    FROM legal_docs_v3\n",
    "    ORDER BY embedding <#> %s::vector\n",
    "    LIMIT %s;\n",
    "    \"\"\"\n",
    "    cursor.execute(query, (user_vector, user_vector, top_k))\n",
    "    rows = cursor.fetchall()\n",
    "    results = pd.DataFrame(rows, columns=[\"Content\", \"Jurisdiction\", \"Source\", \"Citation\", \"Similarity\"])\n",
    "    return results\n",
    "\n",
    "# --- 11. UI to Accept Query ---\n",
    "input_box = widgets.Textarea(\n",
    "    placeholder='Ask a legal question...',\n",
    "    description='Query:',\n",
    "    layout=widgets.Layout(width='80%', height='100px')\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Search\")\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        print(\"🔍 Searching...\")\n",
    "        result_df = search_query(input_box.value)\n",
    "        display(result_df)\n",
    "\n",
    "button.on_click(on_button_click)\n",
    "\n",
    "display(input_box, button, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814c9850-f772-4e21-a86b-ea533e5a7ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
